{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from mtcnn import MTCNN\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from retinaface import RetinaFace\n",
    "\n",
    "# Set the path to the VGGFace2 dataset\n",
    "orig_dir = \"I:/balanced_vggface2\"\n",
    "\n",
    "# Set the path to the directory where you want to copy the selected images\n",
    "new_dir = \"E:/balanced_vggface2\"\n",
    "\n",
    "# Set the path to the text file to save the selected file paths\n",
    "# txt_path = \"E:/files.txt\"\n",
    "\n",
    "# Set the number of images to select per person\n",
    "num_images = 30\n",
    "\n",
    "# Create a list to store the selected file paths\n",
    "selected_files = []\n",
    "\n",
    "# Create the new directory if it doesn't exist\n",
    "# if not os.path.exists(new_dir):\n",
    "#     os.makedirs(new_dir)\n",
    "\n",
    "# Initialize the MTCNN face detector\n",
    "# detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set the paths to your image dataset folders\n",
    "data_dir = \"I:/balanced_vggface2\"\n",
    "train_dir = 'I:/balanced_vggface2/train'\n",
    "test_dir = 'I:/balanced_vggface2/test'\n",
    "val_dir = 'I:/balanced_vggface2/val'\n",
    "\n",
    "# Set the number of images you want for each category\n",
    "num_train = 20\n",
    "num_test = 5\n",
    "num_val = 5\n",
    "\n",
    "# Get the list of classes in your dataset\n",
    "classes = os.listdir(train_dir)\n",
    "\n",
    "# Create the train, test, and val folders if they don't already exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "# # Loop through each class and copy the images to the appropriate folders\n",
    "# for class_name in tqdm(classes):\n",
    "#     class_path = os.path.join(data_dir, class_name)\n",
    "#     images = os.listdir(class_path)\n",
    "#     random.shuffle(images)  # Shuffle the list of images\n",
    "    \n",
    "#     # Copy images to the train folder\n",
    "#     for image in images[:num_train]:\n",
    "#         src_path = os.path.join(class_path, image)\n",
    "#         dst_path = os.path.join(train_dir, class_name, image)\n",
    "#         os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
    "#         shutil.copy(src_path, dst_path)\n",
    "    \n",
    "#     # Copy images to the test folder\n",
    "#     for image in images[num_train:num_train+num_test]:\n",
    "#         src_path = os.path.join(class_path, image)\n",
    "#         dst_path = os.path.join(test_dir, class_name, image)\n",
    "#         os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
    "#         shutil.copy(src_path, dst_path)\n",
    "    \n",
    "#     # Copy images to the validation folder\n",
    "#     for image in images[num_train+num_test:num_train+num_test+num_val]:\n",
    "#         src_path = os.path.join(class_path, image)\n",
    "#         dst_path = os.path.join(val_dir, class_name, image)\n",
    "#         os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
    "#         shutil.copy(src_path, dst_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnx\n",
    "# import warnings\n",
    "# from onnx_tf.backend import prepare\n",
    "# import numpy as np\n",
    "# from datetime import datetime\n",
    "# import tensorflow as tf\n",
    "# import os\n",
    "# import cv2\n",
    "# from tqdm import tqdm\n",
    "# import PIL\n",
    "# from PIL import Image\n",
    "\n",
    "# onnx_model = onnx.load('F:/test/onnx_tensorflow/model.onnx')\n",
    "# tf_rep = prepare(onnx_model) # Import the ONNX model to Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8907/8907 [00:06<00:00, 1342.22it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "# Set the path to the directory where you want to copy the selected images\n",
    "new_dir = \"I:/balanced_vggface2\"\n",
    "\n",
    "all_ids_dict = dict()\n",
    "\n",
    "for id in tqdm(classes):\n",
    "    if id in ['train', 'test', 'val']:\n",
    "        continue\n",
    "    all_ids_dict[id] = {'train':[], 'test':[], 'val':[]}\n",
    "    for file in os.listdir(os.path.join(new_dir, 'train', id))[:num_train]:\n",
    "        all_ids_dict[id]['train'].append(os.path.join(new_dir, 'train', id, file))\n",
    "    for file in os.listdir(os.path.join(new_dir, 'test', id))[:num_test]:\n",
    "        all_ids_dict[id]['test'].append(os.path.join(new_dir, 'test', id, file))\n",
    "    for file in os.listdir(os.path.join(new_dir, 'val', id))[:num_val]:\n",
    "        all_ids_dict[id]['val'].append(os.path.join(new_dir, 'val', id, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "os.makedirs(os.path.join('.', 'vggface2'))\n",
    "with open(os.path.join('.', 'vggface2', 'all_id_files.json'), 'w') as fp:\n",
    "    json.dump(all_ids_dict, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f = open(os.path.join('.', 'vggface2', 'all_id_files.json'), \"r\")\n",
    "\n",
    "# Reading from file\n",
    "all_ids_dict = json.loads(f.read())\n",
    "\n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(all_ids_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8907/8907 [2:23:16<00:00,  1.04it/s]  \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "\n",
    "dataset_path = 'I:/balanced_vggface2'\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create an inception resnet (in eval mode):\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "\n",
    "os.makedirs(os.path.join(dataset_path, 'new_embeddings', 'train'), exist_ok=True)\n",
    "os.makedirs(os.path.join(dataset_path, 'new_embeddings', 'test'), exist_ok=True)\n",
    "os.makedirs(os.path.join(dataset_path, 'new_embeddings', 'val'), exist_ok=True)\n",
    "\n",
    "img_size = 160 # 112\n",
    "for d in tqdm(keys[:50000]):\n",
    "    if os.path.isfile(os.path.join(dataset_path, 'new_embeddings', 'val', d + '.npz')):\n",
    "        continue\n",
    "\n",
    "    image_list = []\n",
    "    for img_path in all_ids_dict[d]['train']:\n",
    "        img = Image.open(img_path)\n",
    "        x_train = tf.image.resize(np.array(img), (img_size, img_size), method=\"nearest\")\n",
    "        x_train = (tf.cast(x_train, tf.float32) - 127.5) / 128.\n",
    "        x_train = tf.transpose(x_train, perm=[2, 0, 1])\n",
    "        x_train = tf.expand_dims(x_train, 0)\n",
    "        image_list.extend(x_train.cpu().numpy())\n",
    "\n",
    "    for img_path in all_ids_dict[d]['test']: \n",
    "        img = Image.open(img_path)\n",
    "        x_test = tf.image.resize(np.array(img), (img_size, img_size), method=\"nearest\")\n",
    "        x_test = (tf.cast(x_test, tf.float32) - 127.5) / 128.\n",
    "        x_test = tf.transpose(x_test, perm=[2, 0, 1])\n",
    "        x_test = tf.expand_dims(x_test, 0)\n",
    "        image_list.extend(x_test.cpu().numpy())\n",
    "\n",
    "    for img_path in all_ids_dict[d]['val']: \n",
    "        img = Image.open(img_path)\n",
    "        x_val = tf.image.resize(np.array(img), (img_size, img_size), method=\"nearest\")\n",
    "        x_val = (tf.cast(x_val, tf.float32) - 127.5) / 128.\n",
    "        x_val = tf.transpose(x_val, perm=[2, 0, 1])\n",
    "        x_val = tf.expand_dims(x_val, 0)\n",
    "        image_list.extend(x_val.cpu().numpy())\n",
    "        \n",
    "    # id_emb = tf_rep.run(np.array(image_list))._0\n",
    "    id_emb = tuple(torch.Tensor(image_list))\n",
    "    id_emb = torch.stack(id_emb).cuda()\n",
    "    id_emb = resnet(id_emb).detach().cpu().numpy()\n",
    "    np.savez_compressed(os.path.join(dataset_path, 'new_embeddings', 'train', d + '.npz'), res=id_emb[:20])\n",
    "    np.savez_compressed(os.path.join(dataset_path, 'new_embeddings', 'test', d + '.npz'), res=id_emb[20:25])\n",
    "    np.savez_compressed(os.path.join(dataset_path, 'new_embeddings', 'val', d + '.npz'), res=id_emb[25:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcface-tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
